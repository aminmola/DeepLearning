{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "An4MzlHK5CN_"
   },
   "source": [
    "### Decision tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "7FlKz8CS4xQt"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LpU_lJ5WkKyV"
   },
   "source": [
    "حال در زیر توابع لازم از جمله آنتروپی و بهره اطلاعاتی را تکمیل کنید.\n",
    "از این توابع در تعریف کردن مدل یادگیری و انتخاب بهترین ویژگی استفاده خواهیم کرد."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "zo-Z8jx145qp"
   },
   "outputs": [],
   "source": [
    "# (10 Points)\n",
    "import math\n",
    "def entropy(y: pd.Series):\n",
    "    \"\"\"\n",
    "    return the entropy of input\n",
    "    \"\"\"\n",
    "    _, counts = np.unique(y, return_counts = True)\n",
    "    m = len(y)\n",
    "    class_probabilities = counts / m\n",
    "    e = -np.sum(class_probabilities * np.log2(class_probabilities))\n",
    "    return e\n",
    "\n",
    "\n",
    "def information_gain(x: pd.Series, y: pd.Series):\n",
    "    \"\"\"\n",
    "    return the information gain of x\n",
    "    \"\"\"\n",
    "    df = pd.DataFrame({'x': x, 'y': y})\n",
    "#     mean = np.mean(x)    \n",
    "#     temp_df1 = df[df['x'] <= mean]\n",
    "#     temp_df2 = df[df['x'] > mean]\n",
    "    q1 = np.percentile(df['x'], 25)\n",
    "    q2 = np.percentile(df['x'], 50)\n",
    "    q3 = np.percentile(df['x'], 75) \n",
    "    temp_df1 = df[df['x'] <= q1]\n",
    "    temp_df2 = df[ (df['x'] > q1) & (df['x'] <= q2) ]\n",
    "    temp_df3 = df[ (df['x'] > q2) & (df['x'] <= q3) ]\n",
    "    temp_df4 = df[ df['x'] > q3]\n",
    "    info_gain = entropy(y) - ((temp_df1.shape[0]/ df.shape[0]) * entropy(temp_df1[\"y\"]) +\n",
    "                              (temp_df2.shape[0]/ df.shape[0]) * entropy(temp_df2[\"y\"])+\n",
    "                             (temp_df3.shape[0]/ df.shape[0]) * entropy(temp_df3[\"y\"])+\n",
    "                             (temp_df4.shape[0]/ df.shape[0]) * entropy(temp_df4[\"y\"]))\n",
    "    return info_gain\n",
    "\n",
    "def information_gains(X: pd.DataFrame, y: pd.Series):\n",
    "    \"\"\"\n",
    "    return the information gain of all features\n",
    "    \"\"\"\n",
    "    info_gains = []\n",
    "    for i in X.columns: \n",
    "        info_gains.append(information_gain(X[i], y ))\n",
    "    return info_gains\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wG7jocWp48AR"
   },
   "source": [
    "<div dir=rtl>\n",
    "حال در زیر کلاس Node  را تعریف میکنیم که  بیس اصلی مدل ما را تشکیل میدهد .\n",
    "\n",
    "با استفاده از توابعی که در قسمت قبل نوشتید مدل یادگیری خود را کامل کنید."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "kfO6sYVt497J"
   },
   "outputs": [],
   "source": [
    "# you can add any variable or function to class if you need.\n",
    "class Node:\n",
    "    def __init__(self, depth):\n",
    "        self.depth = depth\n",
    "        self.tree = None\n",
    "        self.max_depth = 5\n",
    "    def _is_leaf(self):\n",
    "        return len(self.children) == 0        \n",
    "    \n",
    "    def fit(self, X_train, y_train):\n",
    "        self.tree =  self.fit_1(X_train, y_train)\n",
    "        \n",
    "    def fit_1(self, X_train, y_train, depth = 0 ):\n",
    "        \n",
    "        if depth == self.max_depth or len(set(y_train)) == 1:\n",
    "            return {'leaf': True, 'class': y_train.value_counts().index[0]}\n",
    "        best_split = self.find_best_split(X_train, y_train)\n",
    "#         if best_split is None:\n",
    "#             return {'leaf': True, 'class': y_train.value_counts().index[0]}\n",
    "        feature, thresholds, first, second, thirth, fourth  = best_split\n",
    "        # Subtrees \n",
    "        subtree1 = self.fit_1(first.drop('y', axis=1), first['y'], depth + 1)\n",
    "        subtree2 = self.fit_1(second.drop('y', axis=1), second['y'],depth + 1)\n",
    "        subtree3 = self.fit_1(thirth.drop('y', axis=1), thirth['y'],depth + 1)\n",
    "        subtree4 = self.fit_1(fourth.drop('y', axis=1), fourth['y'],depth + 1)\n",
    "        return {\n",
    "            'leaf': False,\n",
    "            'feature': feature,\n",
    "            'thresholds': thresholds,\n",
    "            f'subtree1': subtree1,\n",
    "            f'subtree2': subtree2,\n",
    "            f'subtree3': subtree3,\n",
    "            f'subtree4':subtree4\n",
    "    }\n",
    "    \n",
    "    def find_best_split(self, X_train, y_train):\n",
    "        output = y_train.rename(\"y\")\n",
    "        my_df = pd.concat([X_train, output], axis=1)\n",
    "        info_gains = information_gains(X_train,y_train)\n",
    "        best_feature = X_train.columns[info_gains.index(max(info_gains))]\n",
    "        q1 = np.percentile(my_df[best_feature], 25)  \n",
    "        q2 = np.percentile(my_df[best_feature], 50)  \n",
    "        q3 = np.percentile(my_df[best_feature], 75) \n",
    "        thresholds = [q1,q2,q3]\n",
    "        sub_tree1 = my_df[my_df[best_feature] <= q1]\n",
    "        sub_tree2 = my_df[ (my_df[best_feature] > q1) & (my_df[best_feature] <= q2) ]\n",
    "        sub_tree3 = my_df[ (my_df[best_feature] > q2) & (my_df[best_feature] <= q3) ]\n",
    "        sub_tree4 = my_df[ my_df[best_feature] > q3]\n",
    "        \n",
    "        sub_tree1 = sub_tree1.drop(best_feature, axis=1)\n",
    "        sub_tree2 = sub_tree2.drop(best_feature, axis=1)\n",
    "        sub_tree3 = sub_tree3.drop(best_feature, axis=1)\n",
    "        sub_tree4 = sub_tree4.drop(best_feature, axis=1)\n",
    "        \n",
    "        return best_feature, thresholds, sub_tree1, sub_tree2, sub_tree3, sub_tree4\n",
    "        \n",
    "    def predict_one(self, x, tree):\n",
    "        if tree['leaf'] : \n",
    "            return tree['class']\n",
    "        else:\n",
    "            if x[tree[\"feature\"]] < tree[\"thresholds\"][0]: \n",
    "                return self.predict_one(x, tree[\"subtree1\"])\n",
    "            if x[tree[\"feature\"]] < tree[\"thresholds\"][1] and x[tree[\"feature\"]] > tree[\"thresholds\"][0]: \n",
    "                return self.predict_one(x, tree[\"subtree2\"])\n",
    "            if x[tree[\"feature\"]] < tree[\"thresholds\"][2] and x[tree[\"feature\"]] > tree[\"thresholds\"][1]: \n",
    "                return self.predict_one(x, tree[\"subtree3\"])\n",
    "            if x[tree[\"feature\"]] > tree[\"thresholds\"][2]: \n",
    "                return self.predict_one(x, tree[\"subtree4\"])\n",
    "                           \n",
    "    def predict(self, X):\n",
    "        out = []\n",
    "        for i in range(X.shape[0]): \n",
    "            out.append(self.predict_one(X.loc[i], self.tree))\n",
    "        return out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RT-sJaaU5KRo"
   },
   "source": [
    "### Training & Testing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "N2SDJ-ov5LIF"
   },
   "source": [
    "<div dir=rtl>\n",
    "حال دیتا ست mnist  را لود کنید و با مدل خود لرن کنید و دقت یادگیری را گزارش دهید.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "urStbrnM5Pv9"
   },
   "outputs": [],
   "source": [
    "from keras.datasets import mnist\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# scale data to [0 ,1]\n",
    "\n",
    "x_train = x_train / ( np.max(x_train) - np.min(x_train))\n",
    "# y_train = y_train / ( np.max(y_train) - np.min(y_train))\n",
    "x_test = x_test / ( np.max(x_test) - np.min(x_test))\n",
    "# y_test = y_test / ( np.max(y_test) - np.min(y_test))\n",
    "\n",
    "\n",
    "#reshape data from 28*28 matrix to 784 array\n",
    "\n",
    "X_train= x_train.reshape(x_train.shape[0], 784)\n",
    "X_test = x_test.reshape(x_test.shape[0], 784)\n",
    "\n",
    "# initializing the pca\n",
    "# implement pca on our data with 10 component\n",
    "# select 10 components for train and test data\n",
    "pca = PCA(n_components=10)\n",
    "X_train = pca.fit_transform(X_train)\n",
    "X_test = pca.fit_transform(X_test)\n",
    "#convert reduced datasets types to dataframe using pd\n",
    "x_train=pd.DataFrame(X_train)\n",
    "x_test=pd.DataFrame(X_test)\n",
    "y_train=pd.DataFrame(y_train)\n",
    "y_test=pd.DataFrame(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "_bHTvAuC5Qxl"
   },
   "outputs": [],
   "source": [
    "dt = Node(depth=0)\n",
    "\n",
    "### fit \n",
    "dt.fit(x_train, y_train[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "fPbcE8F35VEs"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuray =  0.1323\n"
     ]
    }
   ],
   "source": [
    "#############################\n",
    "#   report model accuracy   #\n",
    "#        Your Code          #\n",
    "#############################\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "accuracy = accuracy_score(y_test, dt.predict(x_test))\n",
    "print(\"Accuray = \", accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
