{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "An4MzlHK5CN_"
   },
   "source": [
    "### Decision tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "id": "7FlKz8CS4xQt"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LpU_lJ5WkKyV"
   },
   "source": [
    "حال در زیر توابع لازم از جمله آنتروپی و بهره اطلاعاتی را تکمیل کنید.\n",
    "از این توابع در تعریف کردن مدل یادگیری و انتخاب بهترین ویژگی استفاده خواهیم کرد."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "id": "zo-Z8jx145qp"
   },
   "outputs": [],
   "source": [
    "# (10 Points)\n",
    "import math\n",
    "def entropy(y: pd.Series):\n",
    "    \"\"\"\n",
    "    return the entropy of input\n",
    "    \"\"\"\n",
    "    _, counts = np.unique(y, return_counts = True)\n",
    "    m = len(y)\n",
    "    class_probabilities = counts / m\n",
    "    e = -np.sum(class_probabilities * np.log2(class_probabilities))\n",
    "    return e\n",
    "\n",
    "\n",
    "def information_gain(x: pd.Series, y: pd.Series):\n",
    "    \"\"\"\n",
    "    return the information gain of x\n",
    "    \"\"\"\n",
    "    df = pd.DataFrame({'x': x, 'y': y})\n",
    "#     mean = np.mean(x)    \n",
    "#     temp_df1 = df[df['x'] <= mean]\n",
    "#     temp_df2 = df[df['x'] > mean]\n",
    "    q1 = np.percentile(df['x'], 12.5)\n",
    "    q2 = np.percentile(df['x'], 25)\n",
    "    q3 = np.percentile(df['x'], 37.5) \n",
    "    q4 = np.percentile(df['x'], 50)\n",
    "    q5 = np.percentile(df['x'], 62.5)\n",
    "    q6 = np.percentile(df['x'], 75) \n",
    "    q7 = np.percentile(df['x'], 87.5)\n",
    "    temp_df1 = df[df['x'] <= q1]\n",
    "    temp_df2 = df[ (df['x'] > q1) & (df['x'] <= q2) ]\n",
    "    temp_df3 = df[ (df['x'] > q2) & (df['x'] <= q3) ]\n",
    "    temp_df4 = df[ (df['x'] > q3) & (df['x'] <= q4) ]\n",
    "    temp_df5 = df[ (df['x'] > q4) & (df['x'] <= q5) ]\n",
    "    temp_df6 = df[ (df['x'] > q5) & (df['x'] <= q6) ]\n",
    "    temp_df7 = df[ (df['x'] > q6) & (df['x'] <= q7) ]\n",
    "    temp_df8 = df[ df['x'] > q7]\n",
    "    info_gain = entropy(y) - ((temp_df1.shape[0]/ df.shape[0]) * entropy(temp_df1[\"y\"]) +\n",
    "                              (temp_df2.shape[0]/ df.shape[0]) * entropy(temp_df2[\"y\"])+\n",
    "                             (temp_df3.shape[0]/ df.shape[0]) * entropy(temp_df3[\"y\"])+\n",
    "                              (temp_df4.shape[0]/ df.shape[0]) * entropy(temp_df4[\"y\"])+\n",
    "    (temp_df5.shape[0]/ df.shape[0]) * entropy(temp_df5[\"y\"])+\n",
    "    (temp_df6.shape[0]/ df.shape[0]) * entropy(temp_df6[\"y\"])+\n",
    "    (temp_df7.shape[0]/ df.shape[0]) * entropy(temp_df7[\"y\"])+\n",
    "    (temp_df8.shape[0]/ df.shape[0]) * entropy(temp_df8[\"y\"]))\n",
    "    return info_gain\n",
    "\n",
    "def information_gains(X: pd.DataFrame, y: pd.Series):\n",
    "    \"\"\"\n",
    "    return the information gain of all features\n",
    "    \"\"\"\n",
    "    info_gains = []\n",
    "    for i in X.columns: \n",
    "        info_gains.append(information_gain(X[i], y ))\n",
    "    return info_gains\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wG7jocWp48AR"
   },
   "source": [
    "<div dir=rtl>\n",
    "حال در زیر کلاس Node  را تعریف میکنیم که  بیس اصلی مدل ما را تشکیل میدهد .\n",
    "\n",
    "با استفاده از توابعی که در قسمت قبل نوشتید مدل یادگیری خود را کامل کنید."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "id": "kfO6sYVt497J"
   },
   "outputs": [],
   "source": [
    "# you can add any variable or function to class if you need.\n",
    "class Node:\n",
    "    def __init__(self, depth):\n",
    "        self.depth = depth\n",
    "        self.tree = None\n",
    "        self.max_depth = 4\n",
    "    def _is_leaf(self):\n",
    "        return len(self.children) == 0        \n",
    "    \n",
    "    def fit(self, X_train, y_train):\n",
    "        self.tree =  self.fit_1(X_train, y_train)\n",
    "        \n",
    "    def fit_1(self, X_train, y_train, depth = 0 ):\n",
    "        \n",
    "        if depth == self.max_depth or len(set(y_train)) == 1:\n",
    "            return {'leaf': True, 'class': y_train.value_counts().index[0]}\n",
    "        best_split = self.find_best_split(X_train, y_train)\n",
    "        feature, thresholds, first, second, thirth, fourth,fifth, sixth, seventh, eighth  = best_split\n",
    "        # Subtrees \n",
    "        subtree1 = self.fit_1(first.drop('y', axis=1), first['y'], depth + 1)\n",
    "        subtree2 = self.fit_1(second.drop('y', axis=1), second['y'],depth + 1)\n",
    "        subtree3 = self.fit_1(thirth.drop('y', axis=1), thirth['y'],depth + 1)\n",
    "        subtree4 = self.fit_1(fourth.drop('y', axis=1), fourth['y'],depth + 1)\n",
    "        subtree5 = self.fit_1(fifth.drop('y', axis=1), fifth['y'], depth + 1)\n",
    "        subtree6 = self.fit_1(sixth.drop('y', axis=1), sixth['y'],depth + 1)\n",
    "        subtree7 = self.fit_1(seventh.drop('y', axis=1), seventh['y'],depth + 1)\n",
    "        subtree8 = self.fit_1(eighth.drop('y', axis=1), eighth['y'],depth + 1)\n",
    "        return {\n",
    "            'leaf': False,\n",
    "            'feature': feature,\n",
    "            'thresholds': thresholds,\n",
    "            f'subtree1': subtree1,\n",
    "            f'subtree2': subtree2,\n",
    "            f'subtree3': subtree3,\n",
    "            f'subtree4':subtree4,\n",
    "            f'subtree5': subtree5,\n",
    "            f'subtree6': subtree6,\n",
    "            f'subtree7': subtree7,\n",
    "            f'subtree8':subtree8\n",
    "    }\n",
    "    \n",
    "    def find_best_split(self, X_train, y_train):\n",
    "        output = y_train.rename(\"y\")\n",
    "        my_df = pd.concat([X_train, output], axis=1)\n",
    "        info_gains = information_gains(X_train,y_train)\n",
    "        best_feature = X_train.columns[info_gains.index(max(info_gains))]\n",
    "        q1 = np.percentile(my_df[best_feature], 12.5)  \n",
    "        q2 = np.percentile(my_df[best_feature], 25)  \n",
    "        q3 = np.percentile(my_df[best_feature], 37.5) \n",
    "        q4 = np.percentile(my_df[best_feature], 50) \n",
    "        q5 = np.percentile(my_df[best_feature], 62.5) \n",
    "        q6 = np.percentile(my_df[best_feature], 75) \n",
    "        q7 = np.percentile(my_df[best_feature], 87.5) \n",
    "        \n",
    "        thresholds = [q1,q2,q3,q4,q5,q6,q7]\n",
    "        \n",
    "        sub_tree1 = my_df[my_df[best_feature] <= q1]\n",
    "        sub_tree2 = my_df[ (my_df[best_feature] > q1) & (my_df[best_feature] <= q2) ]\n",
    "        sub_tree3 = my_df[ (my_df[best_feature] > q2) & (my_df[best_feature] <= q3) ]\n",
    "        sub_tree4 = my_df[ (my_df[best_feature] > q3) & (my_df[best_feature] <= q4) ]\n",
    "        sub_tree5 = my_df[ (my_df[best_feature] > q4) & (my_df[best_feature] <= q5) ]\n",
    "        sub_tree6 = my_df[ (my_df[best_feature] > q5) & (my_df[best_feature] <= q6) ]\n",
    "        sub_tree7 = my_df[ (my_df[best_feature] > q6) & (my_df[best_feature] <= q7) ]\n",
    "        sub_tree8 = my_df[ my_df[best_feature] > q7]\n",
    "        \n",
    "        sub_tree1 = sub_tree1.drop(best_feature, axis=1)\n",
    "        sub_tree2 = sub_tree2.drop(best_feature, axis=1)\n",
    "        sub_tree3 = sub_tree3.drop(best_feature, axis=1)\n",
    "        sub_tree4 = sub_tree4.drop(best_feature, axis=1)\n",
    "        sub_tree5 = sub_tree5.drop(best_feature, axis=1)\n",
    "        sub_tree6 = sub_tree6.drop(best_feature, axis=1)\n",
    "        sub_tree7 = sub_tree7.drop(best_feature, axis=1)\n",
    "        sub_tree8 = sub_tree8.drop(best_feature, axis=1)\n",
    "        \n",
    "        return best_feature, thresholds, sub_tree1, sub_tree2, sub_tree3, sub_tree4, sub_tree5, sub_tree6, sub_tree7, sub_tree8\n",
    "        \n",
    "    def predict_one(self, x, tree):\n",
    "        if tree['leaf'] : \n",
    "            return tree['class']\n",
    "        else:\n",
    "            if x[tree[\"feature\"]] < tree[\"thresholds\"][0]: \n",
    "                return self.predict_one(x, tree[\"subtree1\"])\n",
    "            if x[tree[\"feature\"]] < tree[\"thresholds\"][1] and x[tree[\"feature\"]] > tree[\"thresholds\"][0]: \n",
    "                return self.predict_one(x, tree[\"subtree2\"])\n",
    "            if x[tree[\"feature\"]] < tree[\"thresholds\"][2] and x[tree[\"feature\"]] > tree[\"thresholds\"][1]: \n",
    "                return self.predict_one(x, tree[\"subtree3\"])\n",
    "            if x[tree[\"feature\"]] < tree[\"thresholds\"][3] and x[tree[\"feature\"]] > tree[\"thresholds\"][2]: \n",
    "                return self.predict_one(x, tree[\"subtree4\"])\n",
    "            if x[tree[\"feature\"]] < tree[\"thresholds\"][4] and x[tree[\"feature\"]] > tree[\"thresholds\"][3]: \n",
    "                return self.predict_one(x, tree[\"subtree5\"])\n",
    "            if x[tree[\"feature\"]] < tree[\"thresholds\"][5] and x[tree[\"feature\"]] > tree[\"thresholds\"][4]: \n",
    "                return self.predict_one(x, tree[\"subtree6\"])\n",
    "            if x[tree[\"feature\"]] < tree[\"thresholds\"][6] and x[tree[\"feature\"]] > tree[\"thresholds\"][5]: \n",
    "                return self.predict_one(x, tree[\"subtree7\"])\n",
    "            if x[tree[\"feature\"]] > tree[\"thresholds\"][6]: \n",
    "                return self.predict_one(x, tree[\"subtree8\"])\n",
    "                           \n",
    "    def predict(self, X):\n",
    "        out = []\n",
    "        for i in range(X.shape[0]): \n",
    "            out.append(self.predict_one(X.loc[i], self.tree))\n",
    "        return out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RT-sJaaU5KRo"
   },
   "source": [
    "### Training & Testing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "N2SDJ-ov5LIF"
   },
   "source": [
    "<div dir=rtl>\n",
    "حال دیتا ست mnist  را لود کنید و با مدل خود لرن کنید و دقت یادگیری را گزارش دهید.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "id": "urStbrnM5Pv9"
   },
   "outputs": [],
   "source": [
    "from keras.datasets import mnist\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# scale data to [0 ,1]\n",
    "\n",
    "x_train = x_train / ( np.max(x_train) - np.min(x_train))\n",
    "# y_train = y_train / ( np.max(y_train) - np.min(y_train))\n",
    "x_test = x_test / ( np.max(x_test) - np.min(x_test))\n",
    "# y_test = y_test / ( np.max(y_test) - np.min(y_test))\n",
    "\n",
    "\n",
    "#reshape data from 28*28 matrix to 784 array\n",
    "\n",
    "X_train= x_train.reshape(x_train.shape[0], 784)\n",
    "X_test = x_test.reshape(x_test.shape[0], 784)\n",
    "\n",
    "# initializing the pca\n",
    "# implement pca on our data with 10 component\n",
    "# select 10 components for train and test data\n",
    "pca = PCA(n_components=4)\n",
    "X_train = pca.fit_transform(X_train)\n",
    "X_test = pca.fit_transform(X_test)\n",
    "#convert reduced datasets types to dataframe using pd\n",
    "x_train=pd.DataFrame(X_train)\n",
    "x_test=pd.DataFrame(X_test)\n",
    "y_train=pd.DataFrame(y_train)\n",
    "y_test=pd.DataFrame(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "id": "_bHTvAuC5Qxl"
   },
   "outputs": [],
   "source": [
    "dt = Node(depth=0)\n",
    "\n",
    "### fit \n",
    "dt.fit(x_train, y_train[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "id": "fPbcE8F35VEs"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuray =  0.175\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "accuracy = accuracy_score(y_test, dt.predict(x_test))\n",
    "print(\"Accuray = \", accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
