{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":7378216,"sourceType":"datasetVersion","datasetId":4287639}],"dockerImageVersionId":30627,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install hazm","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-01-11T12:42:55.838831Z","iopub.execute_input":"2024-01-11T12:42:55.839224Z","iopub.status.idle":"2024-01-11T12:43:10.837078Z","shell.execute_reply.started":"2024-01-11T12:42:55.839195Z","shell.execute_reply":"2024-01-11T12:43:10.835994Z"},"trusted":true},"execution_count":8,"outputs":[{"name":"stdout","text":"Collecting hazm\n  Obtaining dependency information for hazm from https://files.pythonhosted.org/packages/6a/06/302d69a49f0ea8d5700341fcd5f0630361fe7d8cf17254ff45702ecf6058/hazm-0.9.4-py3-none-any.whl.metadata\n  Downloading hazm-0.9.4-py3-none-any.whl.metadata (8.2 kB)\nCollecting fasttext-wheel<0.10.0,>=0.9.2 (from hazm)\n  Downloading fasttext_wheel-0.9.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.4 MB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.4/4.4 MB\u001b[0m \u001b[31m73.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mta \u001b[36m0:00:01\u001b[0m\n\u001b[?25hRequirement already satisfied: flashtext<3.0,>=2.7 in /opt/conda/lib/python3.10/site-packages (from hazm) (2.7)\nRequirement already satisfied: gensim<5.0.0,>=4.3.1 in /opt/conda/lib/python3.10/site-packages (from hazm) (4.3.2)\nCollecting nltk<4.0.0,>=3.8.1 (from hazm)\n  Downloading nltk-3.8.1-py3-none-any.whl (1.5 MB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.5/1.5 MB\u001b[0m \u001b[31m70.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hRequirement already satisfied: numpy==1.24.3 in /opt/conda/lib/python3.10/site-packages (from hazm) (1.24.3)\nCollecting python-crfsuite<0.10.0,>=0.9.9 (from hazm)\n  Obtaining dependency information for python-crfsuite<0.10.0,>=0.9.9 from https://files.pythonhosted.org/packages/38/1d/c475ba7d11e9735f00eb08e2f5315aa2e21c24cc85a0474c3fd425edef58/python_crfsuite-0.9.10-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata\n  Downloading python_crfsuite-0.9.10-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.2 kB)\nRequirement already satisfied: scikit-learn<2.0.0,>=1.2.2 in /opt/conda/lib/python3.10/site-packages (from hazm) (1.2.2)\nRequirement already satisfied: pybind11>=2.2 in /opt/conda/lib/python3.10/site-packages (from fasttext-wheel<0.10.0,>=0.9.2->hazm) (2.11.1)\nRequirement already satisfied: setuptools>=0.7.0 in /opt/conda/lib/python3.10/site-packages (from fasttext-wheel<0.10.0,>=0.9.2->hazm) (68.1.2)\nRequirement already satisfied: scipy>=1.7.0 in /opt/conda/lib/python3.10/site-packages (from gensim<5.0.0,>=4.3.1->hazm) (1.11.4)\nRequirement already satisfied: smart-open>=1.8.1 in /opt/conda/lib/python3.10/site-packages (from gensim<5.0.0,>=4.3.1->hazm) (6.3.0)\nRequirement already satisfied: click in /opt/conda/lib/python3.10/site-packages (from nltk<4.0.0,>=3.8.1->hazm) (8.1.7)\nRequirement already satisfied: joblib in /opt/conda/lib/python3.10/site-packages (from nltk<4.0.0,>=3.8.1->hazm) (1.3.2)\nRequirement already satisfied: regex>=2021.8.3 in /opt/conda/lib/python3.10/site-packages (from nltk<4.0.0,>=3.8.1->hazm) (2023.8.8)\nRequirement already satisfied: tqdm in /opt/conda/lib/python3.10/site-packages (from nltk<4.0.0,>=3.8.1->hazm) (4.66.1)\nRequirement already satisfied: threadpoolctl>=2.0.0 in /opt/conda/lib/python3.10/site-packages (from scikit-learn<2.0.0,>=1.2.2->hazm) (3.2.0)\nDownloading hazm-0.9.4-py3-none-any.whl (371 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m371.7/371.7 kB\u001b[0m \u001b[31m36.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading python_crfsuite-0.9.10-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.1 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m68.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hInstalling collected packages: python-crfsuite, nltk, fasttext-wheel, hazm\n  Attempting uninstall: nltk\n    Found existing installation: nltk 3.2.4\n    Uninstalling nltk-3.2.4:\n      Successfully uninstalled nltk-3.2.4\n\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\npreprocessing 0.1.13 requires nltk==3.2.4, but you have nltk 3.8.1 which is incompatible.\u001b[0m\u001b[31m\n\u001b[0mSuccessfully installed fasttext-wheel-0.9.2 hazm-0.9.4 nltk-3.8.1 python-crfsuite-0.9.10\n","output_type":"stream"}]},{"cell_type":"code","source":"import hazm \nfrom transformers import GPT2LMHeadModel, GPT2Tokenizer,AdamW\nfrom transformers import AutoTokenizer, AutoConfig, AutoModelWithLMHead\nfrom transformers import AutoTokenizer, GPT2LMHeadModel, GPT2Config\nfrom torch.utils.data import Dataset, DataLoader\nimport torch\nimport torch.nn.functional as F","metadata":{"execution":{"iopub.status.busy":"2024-01-11T12:43:10.839765Z","iopub.execute_input":"2024-01-11T12:43:10.840676Z","iopub.status.idle":"2024-01-11T12:43:24.147007Z","shell.execute_reply.started":"2024-01-11T12:43:10.840629Z","shell.execute_reply":"2024-01-11T12:43:24.146192Z"},"trusted":true},"execution_count":9,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.24.3\n  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n","output_type":"stream"}]},{"cell_type":"code","source":"device = \"cuda\" if torch.cuda.is_available() else \"cpu\"","metadata":{"execution":{"iopub.status.busy":"2024-01-11T12:43:24.148085Z","iopub.execute_input":"2024-01-11T12:43:24.148549Z","iopub.status.idle":"2024-01-11T12:43:24.187816Z","shell.execute_reply.started":"2024-01-11T12:43:24.148524Z","shell.execute_reply":"2024-01-11T12:43:24.186803Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"# Load the pre-trained GPT-2 model and tokenizer\nmodel_name = \"HooshvareLab/gpt2-fa\"\nmodel = GPT2LMHeadModel.from_pretrained(model_name)\ntokenizer = GPT2Tokenizer.from_pretrained(model_name, padding_side = 'left')\ntokenizer.add_special_tokens({'pad_token': ''})  \ntokenizer.pad_token = ''\nnormalizer = hazm.Normalizer(persian_numbers=False)\nmodel.to(device)","metadata":{"execution":{"iopub.status.busy":"2024-01-11T12:43:24.189385Z","iopub.execute_input":"2024-01-11T12:43:24.189841Z","iopub.status.idle":"2024-01-11T12:43:44.467330Z","shell.execute_reply.started":"2024-01-11T12:43:24.189806Z","shell.execute_reply":"2024-01-11T12:43:44.466295Z"},"trusted":true},"execution_count":11,"outputs":[{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/808 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"329c3632639340d0af14945c2b908dbe"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"pytorch_model.bin:   0%|          | 0.00/485M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"3430a75221034235850a7c8a033962e5"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/728 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b4e80aba926d4c00a7632de65007db9e"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"vocab.json:   0%|          | 0.00/1.16M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"8a83087789d44f38b444d4e812fd2404"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"merges.txt:   0%|          | 0.00/875k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"633caea537e64912803b381914c4159e"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"added_tokens.json:   0%|          | 0.00/14.0 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"8bbacd1603d447feb02f7f4a03c7e6f1"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"special_tokens_map.json:   0%|          | 0.00/104 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"5fbb9ed5f4814bde9941b79d9fac00ba"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json:   0%|          | 0.00/2.75M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d83d40e7390e4c188e67ef15144a560b"}},"metadata":{}},{"execution_count":11,"output_type":"execute_result","data":{"text/plain":"GPT2LMHeadModel(\n  (transformer): GPT2Model(\n    (wte): Embedding(42001, 768)\n    (wpe): Embedding(1024, 768)\n    (drop): Dropout(p=0.1, inplace=False)\n    (h): ModuleList(\n      (0-11): 12 x GPT2Block(\n        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n        (attn): GPT2Attention(\n          (c_attn): Conv1D()\n          (c_proj): Conv1D()\n          (attn_dropout): Dropout(p=0.1, inplace=False)\n          (resid_dropout): Dropout(p=0.1, inplace=False)\n        )\n        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n        (mlp): GPT2MLP(\n          (c_fc): Conv1D()\n          (c_proj): Conv1D()\n          (act): NewGELUActivation()\n          (dropout): Dropout(p=0.1, inplace=False)\n        )\n      )\n    )\n    (ln_f): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n  )\n  (lm_head): Linear(in_features=768, out_features=42001, bias=False)\n)"},"metadata":{}}]},{"cell_type":"code","source":"file_path = '/kaggle/input/ferdosi/ferdousi.txt'          \nwith open(file_path, 'r') as file:\n    lines = file.readlines()[2:]\nlen(lines)\ninputs = []\noutputs = []\nfor i in range(len(lines)): \n    if i%4 == 1 :\n        inp = lines[i-1].replace(\"\\n\", \" \") + lines[i].replace(\"\\n\", \" \") \n        inputs.append( normalizer.normalize(inp) )\n    if i%4 == 3 :\n        out = lines[i-1].replace(\"\\n\", \" \") + lines[i].replace(\"\\n\", \" \")\n        outputs.append( normalizer.normalize(out) )","metadata":{"execution":{"iopub.status.busy":"2024-01-11T12:43:44.469735Z","iopub.execute_input":"2024-01-11T12:43:44.470059Z","iopub.status.idle":"2024-01-11T12:43:58.825005Z","shell.execute_reply.started":"2024-01-11T12:43:44.470031Z","shell.execute_reply":"2024-01-11T12:43:58.824140Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"code","source":"tokenized_inputs = tokenizer(inputs, padding=True, truncation=True, return_tensors=\"pt\")\ntokenized_outputs = tokenizer(outputs, padding=True, truncation=True, return_tensors=\"pt\")","metadata":{"execution":{"iopub.status.busy":"2024-01-11T12:43:58.826211Z","iopub.execute_input":"2024-01-11T12:43:58.826509Z","iopub.status.idle":"2024-01-11T12:44:08.967852Z","shell.execute_reply.started":"2024-01-11T12:43:58.826484Z","shell.execute_reply":"2024-01-11T12:44:08.967021Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"code","source":"# Define a custom dataset\nclass CustomDataset(Dataset):\n    def __init__(self, input_sequences, output_sequences, train = True):\n        if train :\n            self.input_sequences = input_sequences['input_ids'][: int(len(input_sequences['input_ids']) * 0.8)]\n            self.input_attentions = input_sequences['attention_mask'][: int(len(input_sequences['input_ids']) * 0.8)]\n            self.output_sequences = output_sequences['input_ids'][: int(len(input_sequences['input_ids']) * 0.8)]\n        if not train:\n            self.input_sequences = input_sequences['input_ids'][int(len(input_sequences['input_ids']) * 0.8) : ]\n            self.input_attentions = input_sequences['attention_mask'][int(len(input_sequences['input_ids']) * 0.8) : ]\n            self.output_sequences = output_sequences['input_ids'][int(len(input_sequences['input_ids']) * 0.8) : ]\n            \n    def __len__(self):\n        return len(self.input_sequences)\n\n    def __getitem__(self, idx):\n        return {\n            'input_ids': self.input_sequences[idx],\n            'attention_mask': self.input_attentions[idx],\n            'labels': self.output_sequences[idx]\n        }\n\n\n# Create instances of the custom dataset\ndataset_train = CustomDataset(tokenized_inputs, tokenized_outputs, train = True)\ndataset_test = CustomDataset(tokenized_inputs, tokenized_outputs, train = False)\n\n# Define your data loader\nbatch_size = 4\ntrain_loader = DataLoader(dataset_train, batch_size = batch_size, shuffle=True)\ntest_loader = DataLoader(dataset_test, batch_size = batch_size, shuffle=True)\n\n","metadata":{"execution":{"iopub.status.busy":"2024-01-11T12:44:08.969172Z","iopub.execute_input":"2024-01-11T12:44:08.969545Z","iopub.status.idle":"2024-01-11T12:44:08.986730Z","shell.execute_reply.started":"2024-01-11T12:44:08.969510Z","shell.execute_reply":"2024-01-11T12:44:08.985572Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"code","source":"for batch in train_loader: \n    print(batch)\n    break","metadata":{"execution":{"iopub.status.busy":"2024-01-11T12:44:08.988135Z","iopub.execute_input":"2024-01-11T12:44:08.988518Z","iopub.status.idle":"2024-01-11T12:44:09.015756Z","shell.execute_reply.started":"2024-01-11T12:44:08.988489Z","shell.execute_reply":"2024-01-11T12:44:09.014749Z"},"trusted":true},"execution_count":15,"outputs":[{"name":"stdout","text":"{'input_ids': tensor([[    5,     5,     5,     5,     5,     5,     5,     5,     5,     5,\n             5, 28016,   287,   330,  5198, 26339,   437, 10280,  6308,   395,\n          3846,   718],\n        [    5,     5,     5,     5,     5,  8033,   730,  2005,   287, 17772,\n           285,   448,   323,   314, 13614,   293,  1234,   293, 27963,   472,\n           285,   448],\n        [    5,     5,     5,     5,     5,     5,     5,     5,     5,     5,\n             5,     5,   286,  9415, 15676,   586,  1677, 25754,   274,   312,\n          1023,  4076],\n        [    5,     5,     5,     5,     5,     5,     5,     5,     5,   286,\n           640,   384, 12959,   521,  5875, 29976,  4540,   561,   451,   858,\n          6414,  1546]]), 'attention_mask': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n        [0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n        [0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]]), 'labels': tensor([[    5,     5,     5,     5,     5,     5,     5,  2984,   273,   580,\n           293, 15721,   580,   287,   540,  4600, 10308,   580,   293,   395,\n           287, 21869],\n        [    5,     5,     5,     5,     5,     5,     5,     5, 17120,   285,\n         12524,   521,   815,   296, 14573,   355, 12605,   412,   544, 20508,\n           293,   762],\n        [    5,     5,     5,     5,     5,     5,     5,     5,     5,     5,\n           286, 35580, 14594,  1752,  2696,   906,   323, 10956,   586,   535,\n           312,  9207],\n        [    5,     5,     5,     5,     5,     5,     5,   316,  3195,   322,\n         14120, 33570,  3537,  7914,  6220,   330,   323, 25479,  1350,   297,\n           355,   580]])}\n","output_type":"stream"}]},{"cell_type":"code","source":"import gc\ntorch.cuda.empty_cache()\n# del model, org_image, changed_image, labels\n\ngc.collect()","metadata":{"execution":{"iopub.status.busy":"2024-01-11T12:44:09.017126Z","iopub.execute_input":"2024-01-11T12:44:09.017457Z","iopub.status.idle":"2024-01-11T12:44:09.250152Z","shell.execute_reply.started":"2024-01-11T12:44:09.017429Z","shell.execute_reply":"2024-01-11T12:44:09.248822Z"},"trusted":true},"execution_count":16,"outputs":[{"execution_count":16,"output_type":"execute_result","data":{"text/plain":"0"},"metadata":{}}]},{"cell_type":"markdown","source":"### Previous result of the model ","metadata":{}},{"cell_type":"code","source":"# Function to generate responses\ndef generate_response(batch):\n    input_ids = batch['input_ids'].to(device)\n    labels = batch['labels'].to(device)\n    attention_mask = batch['attention_mask'].to(device)\n    # Generate response\n    output_sequences = model.generate(\n        input_ids=input_ids,\n        max_length=44,\n        num_return_sequences=1,\n#         no_repeat_ngram_size=2,\n#         temperature=0.7,\n#         top_p=0.9,\n        pad_token_id=tokenizer.pad_token_id,\n        eos_token_id=tokenizer.eos_token_id,\n        attention_mask= attention_mask\n    )\n\n    # Decode the generated responses\n    responses = []\n    for response_id in output_sequences:\n        response = tokenizer.decode(response_id, skip_special_tokens=True)\n        responses.append(response)\n\n    return responses\n\nresponses = generate_response(batch)\nfor response in responses:\n    print('\\n\\n', response)\n","metadata":{"execution":{"iopub.status.busy":"2024-01-11T12:44:09.251818Z","iopub.execute_input":"2024-01-11T12:44:09.252187Z","iopub.status.idle":"2024-01-11T12:44:11.693943Z","shell.execute_reply.started":"2024-01-11T12:44:09.252158Z","shell.execute_reply":"2024-01-11T12:44:11.692991Z"},"trusted":true},"execution_count":17,"outputs":[{"name":"stdout","text":"\n\n برادرش را خواند فرشیدورد سپاهی برون کرد مردان مرد و زنان و زنان و مردان و زنان و مردان و زنان و مردان و زنان و مردان و زنان و مردان\n\n\n همه زیر فرمانش بیچاره‌اند که با سوزش و جنگ و پتیاره‌اند. از این‌ها که بگذریم، این‌ها همه‌ی آن‌ها هستند که به‌خاطر\n\n\n ز گفتار دهقان یکی داستان بپیوندم از گفته باستان‌شناسان و تاریخ‌نویسان است که در آن به بررسی تاریخ و فرهنگ ایران باستان و تاریخ آن پرداخته‌\n\n\n زره دار گردی بیامد دلیر کجا نام اوبود پیروز شیرویه دار و بیامد شیرویه دار و بیامد شیرویه دار و بیامد شیرویه دار و بی\n","output_type":"stream"}]},{"cell_type":"code","source":"learning_rate = 1e-6\noptimizer = AdamW(model.parameters(), lr=learning_rate)\nepoch_number = 5\ntrain_losses = []\nvalid_losses = []\nfor epoch_num in range(epoch_number): \n    model.eval()\n    eval_loss = 0\n    for idx, batch in enumerate(test_loader): \n        input_ids = batch['input_ids'].to(device)\n        labels = batch['labels'].to(device)\n        attention_mask = batch['attention_mask'].to(device)\n        generated_output = model(\n            input_ids = input_ids,\n            attention_mask = attention_mask,\n            labels = labels )  \n        loss = generated_output[0]\n        eval_loss += loss.item()\n    print(f\"Avreage evaluation loss for {epoch_num + 1 }th epoch = \" , eval_loss/idx )\n    valid_losses.append(eval_loss/idx)\n    model.train()\n    total_loss = 0\n    for idx, batch in enumerate(train_loader): \n        optimizer.zero_grad()\n        input_ids = batch['input_ids'].to(device)\n        labels = batch['labels'].to(device)\n        attention_mask = batch['attention_mask'].to(device)\n        generated_output = model(\n            input_ids = input_ids,\n            attention_mask = attention_mask,\n            labels = labels )        \n        loss = generated_output[0]\n        loss.backward()\n        optimizer.step()\n        total_loss += loss.item()\n        if idx%100 ==0: \n            print(f\" loss for the {idx +1}th batch  = \" , loss.item() )\n    print(f\"Avreage train loss for {epoch_num + 1 }th epoch = \" , total_loss/idx )\n    train_losses.append(total_loss/idx)\n\n    ","metadata":{"execution":{"iopub.status.busy":"2024-01-11T12:44:11.695365Z","iopub.execute_input":"2024-01-11T12:44:11.695744Z","iopub.status.idle":"2024-01-11T13:04:46.583307Z","shell.execute_reply.started":"2024-01-11T12:44:11.695709Z","shell.execute_reply":"2024-01-11T13:04:46.582274Z"},"trusted":true},"execution_count":18,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/transformers/optimization.py:429: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n  warnings.warn(\n","output_type":"stream"},{"name":"stdout","text":"Avreage evaluation loss for 1th epoch =  13.830471987878123\n loss for the 1th batch  =  13.811408996582031\n loss for the 101th batch  =  12.000876426696777\n loss for the 201th batch  =  10.206310272216797\n loss for the 301th batch  =  9.012651443481445\n loss for the 401th batch  =  6.790555000305176\n loss for the 501th batch  =  6.594540596008301\n loss for the 601th batch  =  6.55123233795166\n loss for the 701th batch  =  5.537768363952637\n loss for the 801th batch  =  5.538773536682129\n loss for the 901th batch  =  6.689272880554199\n loss for the 1001th batch  =  5.356339931488037\n loss for the 1101th batch  =  5.984127521514893\n loss for the 1201th batch  =  5.513629913330078\n loss for the 1301th batch  =  5.5159382820129395\n loss for the 1401th batch  =  5.309263229370117\n loss for the 1501th batch  =  5.694962024688721\n loss for the 1601th batch  =  5.286073684692383\n loss for the 1701th batch  =  5.540404319763184\n loss for the 1801th batch  =  5.40868616104126\n loss for the 1901th batch  =  5.551284313201904\n loss for the 2001th batch  =  4.888038158416748\n loss for the 2101th batch  =  5.486703395843506\n loss for the 2201th batch  =  5.382134437561035\n loss for the 2301th batch  =  5.585429668426514\n loss for the 2401th batch  =  4.717757701873779\n loss for the 2501th batch  =  5.166102886199951\n loss for the 2601th batch  =  5.419555187225342\n loss for the 2701th batch  =  5.848562717437744\n loss for the 2801th batch  =  5.315138339996338\n loss for the 2901th batch  =  4.863993167877197\n loss for the 3001th batch  =  5.433225154876709\n loss for the 3101th batch  =  5.216866493225098\n loss for the 3201th batch  =  4.972898960113525\n loss for the 3301th batch  =  5.03642463684082\n loss for the 3401th batch  =  5.275121212005615\n loss for the 3501th batch  =  5.051234722137451\n loss for the 3601th batch  =  5.122995376586914\n loss for the 3701th batch  =  5.134162425994873\n loss for the 3801th batch  =  4.783994197845459\n loss for the 3901th batch  =  5.249200344085693\n loss for the 4001th batch  =  4.846974849700928\n loss for the 4101th batch  =  4.9782819747924805\n loss for the 4201th batch  =  4.880098819732666\n loss for the 4301th batch  =  4.4132513999938965\n loss for the 4401th batch  =  5.372253894805908\n loss for the 4501th batch  =  5.499845027923584\n loss for the 4601th batch  =  5.135237216949463\n loss for the 4701th batch  =  4.965381622314453\n loss for the 4801th batch  =  4.698731899261475\n loss for the 4901th batch  =  4.6889824867248535\nAvreage train loss for 1th epoch =  5.732158037827861\nAvreage evaluation loss for 2th epoch =  4.957478267146695\n loss for the 1th batch  =  5.258913993835449\n loss for the 101th batch  =  5.290434837341309\n loss for the 201th batch  =  4.7505927085876465\n loss for the 301th batch  =  5.066452980041504\n loss for the 401th batch  =  5.100358009338379\n loss for the 501th batch  =  4.776857376098633\n loss for the 601th batch  =  4.9711432456970215\n loss for the 701th batch  =  4.788491249084473\n loss for the 801th batch  =  4.773995399475098\n loss for the 901th batch  =  4.743871212005615\n loss for the 1001th batch  =  4.939811706542969\n loss for the 1101th batch  =  4.617867946624756\n loss for the 1201th batch  =  5.063015460968018\n loss for the 1301th batch  =  4.99672269821167\n loss for the 1401th batch  =  5.021361351013184\n loss for the 1501th batch  =  4.814479827880859\n loss for the 1601th batch  =  4.531029224395752\n loss for the 1701th batch  =  5.035475730895996\n loss for the 1801th batch  =  4.855074405670166\n loss for the 1901th batch  =  5.013271808624268\n loss for the 2001th batch  =  4.903130531311035\n loss for the 2101th batch  =  4.742875099182129\n loss for the 2201th batch  =  4.94582986831665\n loss for the 2301th batch  =  5.200758934020996\n loss for the 2401th batch  =  4.582576751708984\n loss for the 2501th batch  =  4.485095024108887\n loss for the 2601th batch  =  4.787286281585693\n loss for the 2701th batch  =  4.699307441711426\n loss for the 2801th batch  =  5.158638954162598\n loss for the 2901th batch  =  4.536957740783691\n loss for the 3001th batch  =  4.643519878387451\n loss for the 3101th batch  =  5.1497321128845215\n loss for the 3201th batch  =  4.388735294342041\n loss for the 3301th batch  =  4.949512481689453\n loss for the 3401th batch  =  5.057326793670654\n loss for the 3501th batch  =  4.567216396331787\n loss for the 3601th batch  =  4.866114139556885\n loss for the 3701th batch  =  4.807449817657471\n loss for the 3801th batch  =  4.766891956329346\n loss for the 3901th batch  =  4.790101528167725\n loss for the 4001th batch  =  4.96014928817749\n loss for the 4101th batch  =  4.965577602386475\n loss for the 4201th batch  =  4.369342803955078\n loss for the 4301th batch  =  5.140804767608643\n loss for the 4401th batch  =  4.6755170822143555\n loss for the 4501th batch  =  4.58271598815918\n loss for the 4601th batch  =  4.709792137145996\n loss for the 4701th batch  =  4.559216499328613\n loss for the 4801th batch  =  4.674276828765869\n loss for the 4901th batch  =  5.044430732727051\nAvreage train loss for 2th epoch =  4.903293730366615\nAvreage evaluation loss for 3th epoch =  4.880169303571024\n loss for the 1th batch  =  5.183473587036133\n loss for the 101th batch  =  4.7730913162231445\n loss for the 201th batch  =  4.44468355178833\n loss for the 301th batch  =  4.707874774932861\n loss for the 401th batch  =  4.525144577026367\n loss for the 501th batch  =  4.651157379150391\n loss for the 601th batch  =  4.519782066345215\n loss for the 701th batch  =  4.921792984008789\n loss for the 801th batch  =  4.888964653015137\n loss for the 901th batch  =  4.73124361038208\n loss for the 1001th batch  =  4.835605621337891\n loss for the 1101th batch  =  5.004098892211914\n loss for the 1201th batch  =  5.077796459197998\n loss for the 1301th batch  =  4.703854560852051\n loss for the 1401th batch  =  4.939737796783447\n loss for the 1501th batch  =  5.563500881195068\n loss for the 1601th batch  =  4.9866204261779785\n loss for the 1701th batch  =  4.888638973236084\n loss for the 1801th batch  =  4.918949604034424\n loss for the 1901th batch  =  4.826196193695068\n loss for the 2001th batch  =  4.655001640319824\n loss for the 2101th batch  =  4.424080848693848\n loss for the 2201th batch  =  4.617382526397705\n loss for the 2301th batch  =  4.5341362953186035\n loss for the 2401th batch  =  4.7750563621521\n loss for the 2501th batch  =  5.1407341957092285\n loss for the 2601th batch  =  4.593578815460205\n loss for the 2701th batch  =  4.923710823059082\n loss for the 2801th batch  =  4.832085609436035\n loss for the 2901th batch  =  4.422831058502197\n loss for the 3001th batch  =  5.546754837036133\n loss for the 3101th batch  =  4.850396156311035\n loss for the 3201th batch  =  4.809539794921875\n loss for the 3301th batch  =  5.281004905700684\n loss for the 3401th batch  =  4.8356146812438965\n loss for the 3501th batch  =  5.178309917449951\n loss for the 3601th batch  =  4.826014995574951\n loss for the 3701th batch  =  4.827148914337158\n loss for the 3801th batch  =  5.146480560302734\n loss for the 3901th batch  =  5.177734375\n loss for the 4001th batch  =  4.706514835357666\n loss for the 4101th batch  =  4.6520867347717285\n loss for the 4201th batch  =  4.691263198852539\n loss for the 4301th batch  =  5.240492343902588\n loss for the 4401th batch  =  5.055117130279541\n loss for the 4501th batch  =  4.563324928283691\n loss for the 4601th batch  =  4.381792068481445\n loss for the 4701th batch  =  4.624749183654785\n loss for the 4801th batch  =  4.612727642059326\n loss for the 4901th batch  =  4.857922077178955\nAvreage train loss for 3th epoch =  4.843398706038152\nAvreage evaluation loss for 4th epoch =  4.8566142320632935\n loss for the 1th batch  =  4.644577503204346\n loss for the 101th batch  =  4.5469794273376465\n loss for the 201th batch  =  4.754672050476074\n loss for the 301th batch  =  4.76848840713501\n loss for the 401th batch  =  5.0453057289123535\n loss for the 501th batch  =  4.62518835067749\n loss for the 601th batch  =  5.181020259857178\n loss for the 701th batch  =  4.458680152893066\n loss for the 801th batch  =  4.888306617736816\n loss for the 901th batch  =  4.937650203704834\n loss for the 1001th batch  =  4.463337421417236\n loss for the 1101th batch  =  4.551427364349365\n loss for the 1201th batch  =  4.576942443847656\n loss for the 1301th batch  =  4.699872970581055\n loss for the 1401th batch  =  4.6196112632751465\n loss for the 1501th batch  =  4.681248188018799\n loss for the 1601th batch  =  4.778716087341309\n loss for the 1701th batch  =  5.0125203132629395\n loss for the 1801th batch  =  4.851021766662598\n loss for the 1901th batch  =  4.8789801597595215\n loss for the 2001th batch  =  4.928793907165527\n loss for the 2101th batch  =  4.918931007385254\n loss for the 2201th batch  =  5.200303077697754\n loss for the 2301th batch  =  4.511037349700928\n loss for the 2401th batch  =  4.852418899536133\n loss for the 2501th batch  =  5.149800777435303\n loss for the 2601th batch  =  4.7474212646484375\n loss for the 2701th batch  =  5.526095390319824\n loss for the 2801th batch  =  4.308098316192627\n loss for the 2901th batch  =  4.569308280944824\n loss for the 3001th batch  =  4.868916988372803\n loss for the 3101th batch  =  4.671957492828369\n loss for the 3201th batch  =  4.559066295623779\n loss for the 3301th batch  =  4.415097236633301\n loss for the 3401th batch  =  4.604789733886719\n loss for the 3501th batch  =  4.590390682220459\n loss for the 3601th batch  =  4.913463115692139\n loss for the 3701th batch  =  4.614926338195801\n loss for the 3801th batch  =  4.406954288482666\n loss for the 3901th batch  =  5.039157390594482\n loss for the 4001th batch  =  5.025590896606445\n loss for the 4101th batch  =  4.357781887054443\n loss for the 4201th batch  =  4.255162715911865\n loss for the 4301th batch  =  5.145684719085693\n loss for the 4401th batch  =  4.8339409828186035\n loss for the 4501th batch  =  4.809333801269531\n loss for the 4601th batch  =  4.996027946472168\n loss for the 4701th batch  =  4.324946880340576\n loss for the 4801th batch  =  5.248429298400879\n loss for the 4901th batch  =  4.624365329742432\nAvreage train loss for 4th epoch =  4.824666444909188\nAvreage evaluation loss for 5th epoch =  4.863889299669573\n loss for the 1th batch  =  4.667294025421143\n loss for the 101th batch  =  4.677974700927734\n loss for the 201th batch  =  4.569738388061523\n loss for the 301th batch  =  4.730756759643555\n loss for the 401th batch  =  4.524908065795898\n loss for the 501th batch  =  4.538904190063477\n loss for the 601th batch  =  4.6311845779418945\n loss for the 701th batch  =  5.004683017730713\n loss for the 801th batch  =  5.102405548095703\n loss for the 901th batch  =  5.226931095123291\n loss for the 1001th batch  =  4.942781448364258\n loss for the 1101th batch  =  4.850070476531982\n loss for the 1201th batch  =  4.644672393798828\n loss for the 1301th batch  =  5.123546600341797\n loss for the 1401th batch  =  5.663315773010254\n loss for the 1501th batch  =  5.424023151397705\n loss for the 1601th batch  =  4.99562931060791\n loss for the 1701th batch  =  4.523099422454834\n loss for the 1801th batch  =  5.015697479248047\n loss for the 1901th batch  =  4.463923454284668\n loss for the 2001th batch  =  4.859315395355225\n loss for the 2101th batch  =  4.758331298828125\n loss for the 2201th batch  =  4.42340087890625\n loss for the 2301th batch  =  4.676479339599609\n loss for the 2401th batch  =  4.950162887573242\n loss for the 2501th batch  =  4.910325050354004\n loss for the 2601th batch  =  5.287442207336426\n loss for the 2701th batch  =  5.1932196617126465\n loss for the 2801th batch  =  4.198823928833008\n loss for the 2901th batch  =  5.168457984924316\n loss for the 3001th batch  =  4.751142501831055\n loss for the 3101th batch  =  4.519229412078857\n loss for the 3201th batch  =  4.700951099395752\n loss for the 3301th batch  =  4.832501411437988\n loss for the 3401th batch  =  4.965235233306885\n loss for the 3501th batch  =  4.767210960388184\n loss for the 3601th batch  =  4.795505523681641\n loss for the 3701th batch  =  4.450507164001465\n loss for the 3801th batch  =  4.6315741539001465\n loss for the 3901th batch  =  4.892701148986816\n loss for the 4001th batch  =  4.9331841468811035\n loss for the 4101th batch  =  4.738751411437988\n loss for the 4201th batch  =  4.685389041900635\n loss for the 4301th batch  =  4.655632972717285\n loss for the 4401th batch  =  5.267839431762695\n loss for the 4501th batch  =  4.590116500854492\n loss for the 4601th batch  =  5.112709999084473\n loss for the 4701th batch  =  4.826651096343994\n loss for the 4801th batch  =  5.2607598304748535\n loss for the 4901th batch  =  4.5733208656311035\nAvreage train loss for 5th epoch =  4.83448663464477\n","output_type":"stream"}]},{"cell_type":"code","source":"import matplotlib.pyplot as plt\n\nepochs = range(1, len(train_losses) + 1)\n\nplt.plot(range(1, len(train_losses) + 1), train_losses, 'b-', label='Training Loss')\nplt.plot(range(1, len(train_losses) + 1), valid_losses, 'r-', label='Validation Loss')\nplt.title('Training and Validation Losses')\nplt.xlabel('Epochs')\nplt.ylabel('Loss')\nplt.legend()\n\n# Show plot\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2024-01-11T13:04:46.584724Z","iopub.execute_input":"2024-01-11T13:04:46.585016Z","iopub.status.idle":"2024-01-11T13:04:46.913037Z","shell.execute_reply.started":"2024-01-11T13:04:46.584992Z","shell.execute_reply":"2024-01-11T13:04:46.912037Z"},"trusted":true},"execution_count":19,"outputs":[{"output_type":"display_data","data":{"text/plain":"<Figure size 640x480 with 1 Axes>","image/png":"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"},"metadata":{}}]},{"cell_type":"code","source":"# Function to generate responses\ntest_loader = DataLoader(dataset_test, batch_size = 16, shuffle=True)\nfor batch in test_loader: \n    break\ndef generate_response(batch):\n    input_ids = batch['input_ids'].to(device)\n    labels = batch['labels'].to(device)\n    attention_mask = batch['attention_mask'].to(device)\n    # Generate response\n    output_sequences = model.generate(\n        input_ids=input_ids,\n        max_length=44,\n        num_return_sequences=1,\n        no_repeat_ngram_size=1,\n        temperature=0.1,\n        top_p=0.9,\n        pad_token_id=tokenizer.pad_token_id,\n        eos_token_id=tokenizer.eos_token_id,\n        attention_mask= attention_mask\n    )\n\n    # Decode the generated responses\n    responses = []\n    for response_id in output_sequences:\n        response = tokenizer.decode(response_id, skip_special_tokens=True)\n        responses.append(response)\n\n    return responses\n\nresponses = generate_response(batch)\nfor response in responses:\n    print('\\n\\n', response)\n","metadata":{"execution":{"iopub.status.busy":"2024-01-11T13:05:08.764097Z","iopub.execute_input":"2024-01-11T13:05:08.764840Z","iopub.status.idle":"2024-01-11T13:05:09.107383Z","shell.execute_reply.started":"2024-01-11T13:05:08.764808Z","shell.execute_reply":"2024-01-11T13:05:09.106449Z"},"trusted":true},"execution_count":27,"outputs":[{"name":"stdout","text":"\n\n بپیچید و بر زد یکی سرد باد به زاری بران جامه بر جان بداد ز از گفت چوست که را‌ اندر او همی شد آن شاه بود با سر پر آمد جهان بچو\n\n\n اگر شهریاری تو چندین دروغ بگویی نگیری بگیتی فروغ و بر به ز از را که‌گر شد همی باست بدان چو دل جهان من شاه بود آن\n\n\n بمارد چنین گفت کز مهتری همی از پی گو کنی داوری و به را ز بر‌ست کهان با آن شاه جهان تو سر بود در چو اندر شد او داد\n\n\n چو برتخت بنشست و کرد آفرین ز نیکی دهش بر جهان‌آفرین به از که با را شاه همی چو شد گفت بودانید ب رزم او دل بدم سپاه تو باد\n\n\n شد آیین گشسب اندران چاره جوی که آن کار را چون دهد رنگ وبوی و به از ز بر‌ با اندر شد شاه کرد گفت تا در پیش او بود تو همیست ب چو\n\n\n از اندازه بر نگذرانی سخن که تو نو به کاری گیتی کهن و از‌ ز را با بدست همی شد آن اندر گفت او بود شاه جهان آمد دل در من چو\n\n\n همه کارهای شما ایزدیست زمردی و ز دانش و بخردیست که از به‌گر بر همی شد اندر را ب با بود تاش بد چو بی او شاهم کرد\n\n\n زمانی همی گفت برساوه شاه چه سود آمد ازجادویی برسپاه و به را بر که زش‌ست اندر شد کرد با بود تو سر ب او در چو آن آید\n\n\n بگوید تو را زاد فرخ همین جهان را به چشم جوانی مبین و ز بر‌ کهست از با تا آن شاه بد بود گفت من همی شد آمد هر سر در او\n\n\n که چون بخت پیروز یاور بود روا باشد ار یار کمتر بود و از به که بر ز با اندرش‌ را شدست گفتگر همی چو آمد سخن دل من شاه\n\n\n ازو باز گشتند با درد و جوش ز تیمار با ناله و با خروش دل به از بر همی که‌ست را شدانش گفت تو بود اندر آمد چو نه پیش کرد در\n\n\n چو پیروز شاهی بلند اختری جهاندار وز نامداران سری و به از که بر راست ز با‌ همی شد بود کرد گفت تو شاه جهان من اندر او دل\n\n\n یکی یادگاری ز ساسانیان که چون او نبندد کمر بر میان و از به‌ گفت با را شاه بد کرد بود اندر شدست سپاهان در تو همی آمد من سر\n\n\n یکی ترک بد پیر نامش قلون که ترکان ورا داشتندی زبون و ز از به بر‌ اندر را همی شد با بود شاهستگر دادش آمد دلان چو در\n\n\n چوبیدار گردید یکسر ز خواب نگیرید بر بد ازین سان شتاب و به که ازست‌ با را همی شد تا ب بودان نه او من شاه جهان کردش آمد\n\n\n به ایوان چو آمد به نزدیک تخت برو شهریار آفرین کرد سخت و ز از را بر که‌ش شاه گفت با او همی بود من توست سپاه بد شد اندر در\n","output_type":"stream"}]},{"cell_type":"code","source":"for batch in test_loader: \n    input_ids = batch['input_ids'].to(device)\n    labels = batch['labels'].to(device)\n    attention_mask = batch['attention_mask'].to(device)\n    break\n    \noutput_sequences = model.generate(\n    input_ids=input_ids,\n    max_length=44,\n    num_return_sequences=1,\n    no_repeat_ngram_size=1,\n    temperature=0.1,\n    top_p=0.9,\n    pad_token_id=tokenizer.pad_token_id,\n    eos_token_id=tokenizer.eos_token_id,\n    attention_mask= attention_mask\n)  \noutput_sequences.shape","metadata":{"execution":{"iopub.status.busy":"2024-01-11T13:05:22.553723Z","iopub.execute_input":"2024-01-11T13:05:22.554118Z","iopub.status.idle":"2024-01-11T13:05:22.885803Z","shell.execute_reply.started":"2024-01-11T13:05:22.554089Z","shell.execute_reply":"2024-01-11T13:05:22.884838Z"},"trusted":true},"execution_count":28,"outputs":[{"execution_count":28,"output_type":"execute_result","data":{"text/plain":"torch.Size([16, 44])"},"metadata":{}}]},{"cell_type":"code","source":"output_sequences[:,22:]\n","metadata":{"execution":{"iopub.status.busy":"2024-01-11T13:04:47.617725Z","iopub.execute_input":"2024-01-11T13:04:47.618060Z","iopub.status.idle":"2024-01-11T13:04:47.631826Z","shell.execute_reply.started":"2024-01-11T13:04:47.618032Z","shell.execute_reply":"2024-01-11T13:04:47.630799Z"},"trusted":true},"execution_count":22,"outputs":[{"execution_count":22,"output_type":"execute_result","data":{"text/plain":"tensor([[  293,   312,   323,   327,   330,   285,   296,   314, 16477,   403,\n           639,   716,   412,   395, 15233,   526,   390, 13052,   449,  1215,\n          1088,  2199],\n        [  293,   312,   323,   355,   303,   330,   285,   526,   390,   288,\n          1215,   314,   639, 15233,   296,   287,   298,   412, 16477,   451,\n           358,   403],\n        [  293,   323,   303,   355,   327,   312,   285, 16477,   296,   314,\n           451, 15233,   403,   399,   395,   287,   526,   390,   288,  1215,\n          1088,   449],\n        [  293,   312,   330,   303,   327,   355,   526,   403,   314, 15233,\n           296, 16477,   639,   288,  1215,   390,   451,   358,   298,  2199,\n         13052,   995],\n        [  312,   323,   355,   330,   358,   285,   296,   395,   322,   403,\n           390,   639,   526,   662, 16477, 13052,   279,   378,   287,  1215,\n           484,   449],\n        [  293,   323,   303,   330,   312,   285,   355,   296, 15233,   314,\n           449,   639, 13052,   484,  1215,   304,   403,   358,   412,   390,\n           397,   298],\n        [  293,   303,   327,   323,   312,   330,   355,   403,   287,   526,\n           304,   395,   288, 16477,   296,  2199,   639, 15233,   274,   390,\n           451,   298],\n        [  293,   312,   303,   285,   327, 15233,   355,   296,   323,   314,\n           451,   390,   287,   403,   449,  1088,  1215,   484,   286, 13052,\n           521,   526],\n        [  293,   303,   323,   355,   327,   312,   296,   285,   288,   403,\n         16477,   330,   314,   390, 15233,  2199,  1215,   304,   279,   378,\n           716,   526],\n        [  330,   355,   323,   303,   312,   287,   285,   288,   314,   390,\n           296,   395,   403, 15233, 16477,   412,   451,   484,   298,  2199,\n           399,   358],\n        [  303,   327,   323,   355,   330,   296,   285, 16477,   390,   314,\n           298,   403,   399,   412,  1215,   449,  1088,   395,   358,   279,\n           451, 15233],\n        [  330,   303,   327,   312,   323,   285,  1215,  1088,   355,   296,\n           287,   403,   314,   288,   526, 15233,   639, 16477,   358,   449,\n           298,   412],\n        [  293,   303,   327,   323,   355,   296,   285,   330,  1215,   639,\n         16477,   314,   403, 15233,  2199,   287,   526,   395,   716,   298,\n           449,   390],\n        [  293,   312,   303,   327,   323,   355,   314,   330, 16477,   403,\n           296,  1215,   287,   390,   288,   304,   639,  2199, 13052,   495,\n           526,   412],\n        [  303,   312,   327,   330,   355, 15233, 16477,   285,   314,   390,\n           296,   403,   397,   526,   288,   449,   716,   627,   291,   274,\n           451,   395],\n        [  293,   303,   327,   330,   312,   323,   314,   285,   287,   403,\n           288,   355,   296,   397, 16477,  1215,   526, 15233,   378,   279,\n           451,   639]], device='cuda:0')"},"metadata":{}}]},{"cell_type":"code","source":"label_seqs = []\noutput_seqs = []\n\nfor response_id in output_sequences:\n    output_seq = tokenizer.decode(response_id[22:] , skip_special_tokens=True)\n    output_seqs.append(output_seq)\n\nfor label in labels:\n    label_seq = tokenizer.decode(label , skip_special_tokens=True)\n    label_seqs.append(label_seq)","metadata":{"execution":{"iopub.status.busy":"2024-01-11T13:05:31.057019Z","iopub.execute_input":"2024-01-11T13:05:31.057405Z","iopub.status.idle":"2024-01-11T13:05:31.083142Z","shell.execute_reply.started":"2024-01-11T13:05:31.057373Z","shell.execute_reply":"2024-01-11T13:05:31.082174Z"},"trusted":true},"execution_count":29,"outputs":[]},{"cell_type":"code","source":"!pip install rouge\n","metadata":{"execution":{"iopub.status.busy":"2024-01-11T13:04:47.666334Z","iopub.execute_input":"2024-01-11T13:04:47.667386Z","iopub.status.idle":"2024-01-11T13:04:59.524696Z","shell.execute_reply.started":"2024-01-11T13:04:47.667350Z","shell.execute_reply":"2024-01-11T13:04:59.523451Z"},"trusted":true},"execution_count":25,"outputs":[{"name":"stdout","text":"Requirement already satisfied: rouge in /opt/conda/lib/python3.10/site-packages (1.0.1)\nRequirement already satisfied: six in /opt/conda/lib/python3.10/site-packages (from rouge) (1.16.0)\n","output_type":"stream"}]},{"cell_type":"markdown","source":"Recall-Oriented Understudy for Gisting Evaluation ","metadata":{}},{"cell_type":"code","source":"from rouge import Rouge\n\ndef calculate_rouge_scores(candidate, reference):\n    rouge = Rouge()\n    scores = rouge.get_scores(candidate, reference)\n    return scores\n\n# Example reference and candidate sentences\nreference = 'Reference sentence for evaluation.'\ncandidate = 'Generated sentence for evaluation.'\n\n# Calculate ROUGE scores\nrouge_scores = calculate_rouge_scores(output_seqs, label_seqs)\n\n# Print ROUGE scores\nprint(rouge_scores[0]['rouge-1'])","metadata":{"execution":{"iopub.status.busy":"2024-01-11T13:08:36.667983Z","iopub.execute_input":"2024-01-11T13:08:36.668380Z","iopub.status.idle":"2024-01-11T13:08:36.683352Z","shell.execute_reply.started":"2024-01-11T13:08:36.668350Z","shell.execute_reply":"2024-01-11T13:08:36.682279Z"},"trusted":true},"execution_count":34,"outputs":[{"name":"stdout","text":"{'r': 0.21428571428571427, 'p': 0.15789473684210525, 'f': 0.18181817693296617}\n","output_type":"stream"}]}]}